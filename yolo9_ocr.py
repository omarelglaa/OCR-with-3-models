# -*- coding: utf-8 -*-
"""yolo9 ocr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FE9p4-XQAKWdxtjmliJBPdxYyQmul-GA

# ***Tesseract***
"""

!pip install PyPDF2

!pip install gradio

import gradio as gr
import PyPDF2
import numpy as np

# Gradio interface creation
interface = gr.Interface(
    fn=extract,
    inputs="file",  # Specify input type
    outputs="text",
    elem_id="upload",  # Assign an element ID for customization (optional)
    title="PDF Text Classification",  # Use 'title' instead of 'label'
    description="Upload a PDF file to extract text and get its classification.",
)

# Customize output (optional)
def format_output(outputs):
    if not outputs:
        return "No text found in the PDF."
    output_text = ""
    for text, class_name, class_prob in outputs:
        output_text += f"Class: {class_name} \n Text: {text}\n\n\n"
    return output_text

demo = gr.Interface(fn=extract, inputs="file", outputs="text")
demo.launch()

from ultralytics import YOLO

from IPython.display import display, Image
from ultralytics.utils.plotting import Annotator, colors
import cv2
import os
import pytesseract
import pandas as pd

model = YOLO('yolov8_detect_4classes_86map.pt')
names = model.names
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
names = model.names

def extract(path):
    text = []
    clas = []
    im = []
    results = model(path)
    #img = cv2.imread(path)

    # Extract bounding boxes
    boxes = results[0].boxes.xyxy.tolist()
    clss = results[0].boxes.cls.cpu().tolist()
    #annotator = Annotator(img, line_width=2, example=names)

    # Iterate through the bounding boxes
    for box, cls in zip(boxes, clss):
        x1, y1, x2, y2 = box
        # Crop the object using the bounding box coordinates
        ultralytics_crop_object = path[int(y1):int(y2), int(x1):int(x2)]

        im.append(ultralytics_crop_object)

        #idx += 1
        #annotator.box_label(box, color=colors(int(cls), True), label=names[int(cls)])

            # Adding custom options
        custom_config = r'--oem 3 --psm 6'
        text.append(pytesseract.image_to_string(ultralytics_crop_object, config=custom_config))
        clas.append(names[int(cls)])

    return text , clas , im

import PIL
import fitz
import numpy as np
import pandas as pd

def xx(file_path) :
    doc = fitz.open(file_path)  # open document
    text = []
    classes = []
    im = []
    for i, page in enumerate(doc):
        pix = page.get_pixmap()  # render page to an image
        #img = cv2.imread(pix)
        #pix.save(f"page_{i}.png")
        pix = PIL.Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        pix = np.array(pix)

        t , c , i = extract(pix)
        text.append(t)
        classes.append(c)
        im.append(i)

    text = [item for sublist in text for item in sublist]
    classes = [item for sublist in classes for item in sublist]
    im = [item for sublist in im for item in sublist]
    txt = ""
    for i in len(text) :
        txt+=f"Section : { classes } \n text : {text[i] } \n\n*************************************************************"
    return txt

import PIL
import fitz
import numpy as np
import pandas as pd

file_path ="1705067515471.pdf"
doc = fitz.open(file_path)  # open document
text = []
classes = []
im = []
for i, page in enumerate(doc):
    pix = page.get_pixmap()  # render page to an image
    #img = cv2.imread(pix)
    #pix.save(f"page_{i}.png")
    pix = PIL.Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
    pix = np.array(pix)

    t , c , i = extract(pix)
    text.append(t)
    classes.append(c)
    im.append(i)

text = [item for sublist in text for item in sublist]
classes = [item for sublist in classes for item in sublist]
im = [item for sublist in im for item in sublist]

df = pd.DataFrame({'Text': text, 'Class': classes})
df


    #cv2.show_image(pix)

print(df['Text'][0])















import re
def classify_text(text):
    # Define patterns for each class
    experience_pattern = r'\b(?:work\s*experience|experience\s*professionnelle|career\s*summary|résumé\s*de\s*carrière|key\s*responsibilities|responsabilités\s*clés|key\s*achievements|réalisation\s*clés|projets? d\'intégration|stage|stagiaire|tâches?\s*effectuées?|tâches?\s*réalisées?)\b'
    projects_pattern = r'\b(?:projects|project\s*experience|projets|expérience\s*de\s*projet)\b'
    skills_pattern = r'\b(?:skills|skill\s*set|compétences|compétence|informatique)\b'
    certificate_pattern = r'\b(?:certificate|certifications|certificat|certifications)\b'


    # Match patterns in the text
    if re.search(experience_pattern, text, re.IGNORECASE):
        return "Experience"
    elif re.search(projects_pattern, text, re.IGNORECASE):
        return "Projects"
    elif re.search(skills_pattern, text, re.IGNORECASE):
        return "Skills"
    elif re.search(certificate_pattern, text, re.IGNORECASE):
        return "Certificate"
    else:
        return "Unknown"

def classify_resume(resume_texts):
    classified_texts = []
    for text in resume_texts:
        classification = classify_text(text)
        classified_texts.append((text, classification))
    return classified_texts

text , clas = extract("C:/Users/trabe/Downloads/Lettings-Administrator-CV-1.png")
#print(classified_resume)
# Create a DataFrame from the classified texts
#df = pd.DataFrame(classified_resume, columns=["Text", "Class"])

#print(df)
print(text)
print(clas)

classified_resume = extract("C:/Users/trabe/OneDrive/Bureau/Capture d'écran 2024-04-01 033041.png")
#print(classified_resume)
# Create a DataFrame from the classified texts
df = pd.DataFrame(classified_resume, columns=["Text", "Class"])

print(df)

classified_resume = extract("C:/Users/trabe/Downloads/1639748048896.jpg")
#print(classified_resume)
# Create a DataFrame from the classified texts
df = pd.DataFrame(classified_resume, columns=["Text", "Class"])

print(df)

classified_resume = extract("C:/Users/trabe/Downloads/1666966905196.jpg")
#print(classified_resume)
# Create a DataFrame from the classified texts
df = pd.DataFrame(classified_resume, columns=["Text", "Class"])

print(df)

df['Text'][1]

results = model("C:/Users/trabe/Downloads/1666966905196.jpg")  # return a list of Results objects

# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen

"""# ***easy OCR***"""

import easyocr

reader = easyocr.Reader(['en','fr'])

def extract1(path):
    text = []
    results = model(path)
    #img = cv2.imread(path)

    # Extract bounding boxes
    boxes = results[0].boxes.xyxy.tolist()

    # Iterate through the bounding boxes
    for i, box in enumerate(boxes):
        txt = ""
        x1, y1, x2, y2 = box
        # Crop the object using the bounding box coordinates
        ultralytics_crop_object = img[int(y1):int(y2), int(x1):int(x2)]


            # Adding custom options
        custom_config = r'--oem 3 --psm 6'
        #text.append(pytesseract.image_to_string(ultralytics_crop_object, config=custom_config))
        bounds = reader.readtext(ultralytics_crop_object)
        for res in bounds:
            det, conf = res[1], res[2]
            txt = txt + '\n' + det
        text.append(txt)
        #im = plt.imread(r'D:\OCR_different_approach\font_text_sizes.jpg')
        #plt.imshow(im)

    return classify_resume(text)
    #return classify_resume(text)

t = extract1("C:/Users/trabe/Downloads/1639748048896.jpg")

t



"""# Nougat"""

pip install nougat-ocr

!nougat D:\9raya\Stage_PFE\ultralytics_crop_1.jpg

!pip install PyMuPDF

from paddleocr import PaddleOCR,draw_ocr
# Paddleocr supports Chinese, English, French, German, Korean and Japanese.
# You can set the parameter `lang` as `ch`, `en`, `fr`, `german`, `korean`, `japan`
# to switch the language model in order.
ocr = PaddleOCR(lang='en') # need to run only once to download and load model into memory

img_path = "ultralytics_crop_0.jpg"

result = ocr.ocr(img_path, cls=False)

for idx in range(len(result)):
    res = result[idx]
    for line in res:
        print(line)

!paddleocr --image_dir ultralytics_crop_0.jpg --use_angle_cls true --lang en

